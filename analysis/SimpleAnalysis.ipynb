{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sencoder as sen\n",
    "import numpy as np\n",
    "import os\n",
    "import tokenizer as tok\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.kl import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greetings\n",
      "['how', 'do', 'you', 'do', 'kind', 'man', '?']\n",
      "['how', 'are', 'you', 'doing', 'today', '?']\n",
      "['what', 'is', 'going', 'on', '?']\n",
      "['good', 'morning', 'dear', ',', 'It', 'is', 'a', 'pleasure', 'to', 'see', 'you']\n",
      "['how', 'is', 'it', 'going', '?']\n",
      "\n",
      "commands\n",
      "['do', 'not', 'go', 'into', 'the', 'forest', '.']\n",
      "['you', 'must', 'cut', 'down', 'this', 'tree', '.']\n",
      "['build', 'a', 'house', 'from', 'the', 'wood', '.']\n",
      "['go', 'into', 'that', 'cave', '.']\n",
      "\n",
      "ramblings\n",
      "['it', 'is', 'god', \"'\", 's', 'will', ',', 'to', 'be', 'killed', 'or', 'to', 'be', 'lived', '.']\n",
      "['the', 'subject', 'of', 'good', 'an', 'evil', 'cannot', 'be', 'contained', '.']\n",
      "['the', 'herd', 'will', 'not', 'see', 'the', 'truths', 'that', 'stare', 'them', 'in', 'the', 'face', '.']\n",
      "['death', 'will', 'come', 'to', 'those', 'who', 'wait', '.']\n",
      "['life', 'is', 'tedious', 'and', 'brief', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_strs = {\"greetings\":[\"how do you do kind man?\", \n",
    "                            \"how are you doing today?\",\n",
    "                            \"what is going on?\",\n",
    "                            \"good morning dear, It is a pleasure to see you\",\n",
    "                            \"how is it going?\"],\n",
    "                \"commands\":[\"do not go into the forest.\",\n",
    "                            \"you must cut down this tree.\",\n",
    "                            \"build a house from the wood.\",\n",
    "                            \"go into that cave.\"\n",
    "                            ],\n",
    "                \"ramblings\":[\"it is god's will, to be killed or to be lived.\",\n",
    "                            \"the subject of good an evil cannot be contained.\",\n",
    "                            \"the herd will not see the truths that stare them in the face.\",                    \n",
    "                            \"death will come to those who wait.\",                  \n",
    "                            \"life is tedious and brief.\"                           \n",
    "                            ]\n",
    "                }\n",
    "\n",
    "tokens = {k:[tok.tokenize(s) for s in v] for k,v in sample_strs.items()}           \n",
    "\n",
    "for k,v in tokens.items():\n",
    "    print(k)\n",
    "    for vv in v:\n",
    "        print(vv)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqAutoencoder(\n",
       "  (word_encoder): WordEncoder(\n",
       "    (encoder): Linear(in_features=100, out_features=600, bias=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (rssm): RSSM(\n",
       "      h_size=300, s_size=300, emb_size=100, min_sigma=0.0001\n",
       "      (rnn): GRUCell(\n",
       "        (gru): GRUCell(400, 300)\n",
       "      )\n",
       "      (state_layer): Linear(in_features=300, out_features=600, bias=True)\n",
       "    )\n",
       "    (attention): Linear(in_features=600, out_features=1, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (rssm): RSSM(\n",
       "      h_size=300, s_size=300, emb_size=400, min_sigma=0.0001\n",
       "      (rnn): GRUCell(\n",
       "        (gru): GRUCell(700, 300)\n",
       "      )\n",
       "      (state_layer): Linear(in_features=300, out_features=600, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): SimpleClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=5760, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=5760, out_features=11521, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepath = \"../training_scripts/\"\n",
    "s = \"attention/attention_0_lr0.005\"\n",
    "s = os.path.join(prepath,s)\n",
    "model, chkpt = sen.io.load_model(s, ret_chkpt=True)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greetings\n",
      "[10188, 2334, 6166, 2334, 11028, 8296, 9917]\n",
      "[10188, 2392, 6166, 9674, 7995, 9917]\n",
      "[10310, 1144, 3098, 8355, 9917]\n",
      "[7532, 3726, 4878, 10810, 4750, 1144, 676, 9795, 7640, 7112, 6166]\n",
      "[10188, 1144, 5711, 3098, 9917]\n",
      "\n",
      "commands\n",
      "[2334, 9351, 1003, 1853, 1116, 3711, 9082]\n",
      "[6166, 3123, 4804, 915, 8294, 4764, 9082]\n",
      "[3308, 676, 4631, 8051, 1116, 5422, 9082]\n",
      "[1003, 1853, 11406, 1273, 9082]\n",
      "\n",
      "ramblings\n",
      "[5711, 1144, 8704, 1938, 1413, 4595, 10810, 7640, 4017, 4758, 6814, 7640, 4017, 6908, 9082]\n",
      "[1116, 5159, 5589, 7532, 4779, 10008, 6299, 4017, 3590, 9082]\n",
      "[1116, 2122, 4595, 9351, 7112, 1116, 3068, 11406, 3524, 8345, 7280, 1116, 11514, 9082]\n",
      "[4500, 4595, 10377, 7640, 390, 3421, 59, 9082]\n",
      "[7542, 1144, 7531, 9894, 10814, 9082]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2idx = chkpt['word2idx']\n",
    "idx2word = chkpt['idx2word']\n",
    "wordidxs = {k:[[word2idx[w] for w in t] for t in v]\\\n",
    "                            for k,v in tokens.items()}\n",
    "for k,v in wordidxs.items():\n",
    "    print(k)\n",
    "    for idxs in v:\n",
    "        print(idxs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: how do you do kind man ?\n",
      "Enc: \n",
      " for of \n",
      " to not to\n",
      "Dec: you but you do matter man ?\n",
      "\n",
      "\n",
      "Real: how are you doing today ?\n",
      "Enc: Or , , , the to\n",
      "Dec: how with ask doing thereby ?\n",
      "\n",
      "\n",
      "Real: what is going on ?\n",
      "Enc: . the \n",
      " the is\n",
      "Dec: if is last on ?\n",
      "\n",
      "\n",
      "Real: good morning dear , It is a pleasure to see you\n",
      "Enc: \n",
      " \n",
      " the in \n",
      " perhaps is and \n",
      " , \n",
      "\n",
      "Dec: called curiosity knowledge , it is a love to see you\n",
      "\n",
      "\n",
      "Real: how is it going ?\n",
      "Enc: - to \n",
      " , to\n",
      "Dec: how is it going ?\n",
      "\n",
      "\n",
      "Real: do not go into the forest .\n",
      "Enc: \n",
      " and \n",
      " churches that be not\n",
      "Dec: do not go into the heart .\n",
      "\n",
      "\n",
      "Real: you must cut down this tree .\n",
      "Enc: \n",
      " , \n",
      " . , be are\n",
      "Dec: must you here than this tree .\n",
      "\n",
      "\n",
      "Real: build a house from the wood .\n",
      "Enc: \n",
      " to \n",
      " them is \n",
      " .\n",
      "Dec: or a healthier on the inclination .\n",
      "\n",
      "\n",
      "Real: go into that cave .\n",
      "Enc: \n",
      " : \n",
      " churches to\n",
      "Dec: go into that cave .\n",
      "\n",
      "\n",
      "Real: it is god ' s will , to be killed or to be lived .\n",
      "Enc: \n",
      " , \n",
      " \n",
      " it ) able be fools not \n",
      " s , not is\n",
      "Dec: it \n",
      " will to never will , , be get or to be better .\n",
      "\n",
      "\n",
      "Real: the subject of good an evil cannot be contained .\n",
      "Enc: The and origin be , evil and man could \n",
      "\n",
      "Dec: the errors of which an act about be conducted .\n",
      "\n",
      "\n",
      "Real: the herd will not see the truths that stare them in the face .\n",
      "Enc: \n",
      " of \n",
      " the . and a of \n",
      " \n",
      " to : , \n",
      "\n",
      "Dec: the earth will do nevertheless so them that forces lacking in the portion .\n",
      "\n",
      "\n",
      "Real: death will come to those who wait .\n",
      "Enc: \n",
      " the are of grief to not .\n",
      "Dec: One will do to those who wait .\n",
      "\n",
      "\n",
      "Real: life is tedious and brief .\n",
      "Enc: The \n",
      " \n",
      " in worth ,\n",
      "Dec: him is objects and painful .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states = {}\n",
    "for k,v in wordidxs.items():\n",
    "    states[k] = []\n",
    "    for idxs in v:\n",
    "        words = [idx2word[idx] for idx in idxs]\n",
    "        print(\"Real:\", \" \".join(words))\n",
    "        idxs = torch.LongTensor(idxs).cuda()\n",
    "        embs = model.embed(idxs)\n",
    "        embs = embs.reshape(1,len(idxs),-1)\n",
    "        enc_hs, enc_mus, enc_sigmas, enc_states = model.encode(embs)\n",
    "        state = Normal(enc_mus[-1], enc_sigmas[-1])\n",
    "        states[k].append(state)\n",
    "        mus = enc_mus.reshape(-1,enc_mus.shape[-1])\n",
    "        sigmas = enc_sigmas.reshape(-1,enc_sigmas.shape[-1])\n",
    "        enc_preds = model.classify(mus, sigmas)\n",
    "        argmaxes = torch.argmax(enc_preds, dim=-1).long()\n",
    "        words = reversed([idx2word[arg.item()] for arg in argmaxes])\n",
    "        print(\"Enc:\", \" \".join(words))\n",
    "        \n",
    "        state = enc_states[-1]\n",
    "        h = (enc_hs[-1],enc_mus[:,-1],enc_sigmas[:,-1])\n",
    "        hs,mus,sigmas = model.decode(state, h, seq_len=len(idxs),\n",
    "                                classifier=model.classifier,\n",
    "                                embeddings=model.embeddings)\n",
    "        mus = torch.stack(mus, dim=1)\n",
    "        mus = mus.reshape(-1,mus.shape[-1])\n",
    "        sigmas = torch.stack(sigmas, dim=1)\n",
    "        sigmas = sigmas.reshape(-1,sigmas.shape[-1])\n",
    "        dec_preds = model.classify(mus, sigmas)\n",
    "        argmaxes = torch.argmax(dec_preds, dim=-1).long()\n",
    "        words = reversed([idx2word[arg.item()] for arg in argmaxes])\n",
    "        print(\"Dec:\", \" \".join(words))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
